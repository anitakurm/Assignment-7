---
title: "Assignment 4 - Coordinating Heart Rate"
author: "Riccardo Fusaroli"
date: "November 6, 2017"
output: html_document
---

```{r libraries include=F}
library(dplyr)
library(ggplot2)
library(crqa) 
library(stringr)
```

## Analysing Heart Rate and Respiration data

The goal of this assignment is to first familiarize you with heart rate, and respiration data and their preprocessing. The second part explores how to analyze interpersonal coordination of these signals.

These are the questions you need to be able to answer at the end of the assignment (aka that you need to submit as part of the portfolio)

1) How do you preprocess heart rate and respiration data? Describe the process. If any data needs to be excluded, list the excluded data and motivate the exclusion.

2) Do you observe interpersonal coordination in heart rate and respiration? Describe your control baseline, the method used to quantify coordination, and the statistical models used to infer whether coordination was higher than in the baseline. Report the results of the models.

3) Do you observe differences in coordination between conditions? Report the models and results.

4) Is respiration coordination a likely driver of heart rate coordination? Describe how you would test for it. Bonus points if you actually r  the tests and report methods and results.

N.B. to give you a bit more data I included data from last year (Study1) and from your class (Study2). Note that synchrono s and turn-taking are the same across both studies, but the third condition is different: last year it was self-paced joint reading; this year it was the tv-series conversation. So you might want to exclude the self-paced reading (but, up to you!)

## Step by step suggestions to solve the assignment

### Exploring physiological signals

- Choose one pair (one pair, three conditions)
- Load the logs

```{r pick a pair}
pair_1_1 = read.csv("Study2_G8_T1_TurnTaking.csv")
pair_1_2 = read.csv("Study2_G8_T2_Synchronous.csv")
pair_1_3 = read.csv("Study2_G8_T3_Conversation.csv")

 unprocess_1_HR=ggplot(pair_1_1,aes(x=time))+
  geom_line(aes(y=HR1,color="red"))+
  geom_line(aes(y=HR2))

 unprocess_2_HR=ggplot(pair_1_2,aes(x=time))+
  geom_line(aes(y=HR1,color="red"))+
  geom_line(aes(y=HR2))

 unprocess_3_HR=ggplot(pair_1_3,aes(x=time))+
  geom_line(aes(y=HR1,color="red"))+
  geom_line(aes(y=HR2))
 
unprocess_1_HR
unprocess_2_HR
unprocess_3_HR
gridExtra::grid.arrange(unprocess_1_HR, unprocess_2_HR, unprocess_3_HR)
```

- Produce a plot of the participants' respiration signal and a different one of the participants' HR signal (for inspecting whether the data is usable)
  N.B: remember the slides: artifacts, downsampling, scaling.
  N.B. The gridExtra::grid.arrange() f ction allows you to display the plots side by side. E.g. grid.arrange(plot1, plot2, plot3, ncol=3)
  
```{r remove outliers}
removeOuts <- function(ts, threshold) {
  ts[ts > (mean(ts, na.rm = T) + (threshold * sd(ts, na.rm = T))) |
  ts < (mean(ts, na.rm = T) - (threshold * sd(ts, na.rm = T)))] = mean(ts, na.rm =
  T)
  return(ts)
}

treshold=1.5

pair_1_1$HR1 = removeOuts(pair_1_1$HR1, treshold)
pair_1_1$HR2 = removeOuts(pair_1_1$HR2, treshold)
pair_1_1$Resp1 = removeOuts(pair_1_1$Resp1,  treshold)
pair_1_1$Resp2 = removeOuts(pair_1_1$Resp2,  treshold)

pair_1_2$HR1 = removeOuts(pair_1_2$HR1,  treshold)
pair_1_2$HR2 = removeOuts(pair_1_2$HR2,  treshold)
pair_1_2$Resp1 = removeOuts(pair_1_2$Resp1,  treshold)
pair_1_2$Resp2 = removeOuts(pair_1_2$Resp2,  treshold)

pair_1_3$HR1 = removeOuts(pair_1_3$HR1,  treshold)
pair_1_3$HR2 = removeOuts(pair_1_3$HR2,  treshold)
pair_1_3$Resp1 = removeOuts(pair_1_3$Resp1,  treshold)
pair_1_3$Resp2 = removeOuts(pair_1_3$Resp2,  treshold)

```
  
```{r downsample}
#downsample
#pacman::p_load(groupdata2)
library(groupdata2)
pair_1_1 = pair_1_1 %>%
  group(n = 100, method = 'greedy') %>%
  summarise(
    time = mean(time, na.rm = T),
    HR1 = mean(HR1, na.rm = T),
    HR2 = mean(HR2, na.rm = T),
    Resp1 = mean(Resp1, na.rm = T),
    Resp2 = mean(Resp2, na.rm = T)
  )

pair_1_2 = pair_1_2 %>%
  group(n = 100, method = 'greedy') %>%
  summarise(
    time = mean(time, na.rm = T),
    HR1 = mean(HR1, na.rm = T),
    HR2 = mean(HR2, na.rm = T),
    Resp1 = mean(Resp1, na.rm = T),
    Resp2 = mean(Resp2, na.rm = T)
  )

pair_1_3 = pair_1_3 %>%
  group(n = 100, method = 'greedy') %>%
  summarise(
    time = mean(time, na.rm = T),
    HR1 = mean(HR1, na.rm = T),
    HR2 = mean(HR2, na.rm = T),
    Resp1 = mean(Resp1, na.rm = T),
    Resp2 = mean(Resp2, na.rm = T)
  )
```


```{r scaling}
#scale
pair_1_1$Resp1S = scale(pair_1_1$Resp1)
pair_1_1$Resp2S = scale(pair_1_1$Resp2)
pair_1_1$HR1S = scale(pair_1_1$HR1)
pair_1_1$HR2S = scale(pair_1_1$HR2)

pair_1_2$Resp1S = scale(pair_1_2$Resp1)
pair_1_2$Resp2S = scale(pair_1_2$Resp2)
pair_1_2$HR1S = scale(pair_1_2$HR1)
pair_1_2$HR2S = scale(pair_1_2$HR2)

pair_1_3$Resp1S = scale(pair_1_3$Resp1)
pair_1_3$Resp2S = scale(pair_1_3$Resp2)
pair_1_3$HR1S = scale(pair_1_3$HR1)
pair_1_3$HR2S = scale(pair_1_3$HR2)

```

```{r plotting}
#Let's plot
process_1_HR=ggplot(pair_1_1,aes(x=time))+
  geom_line(aes(y=HR1S,color="#3366cc"))+
  geom_line(aes(y=HR2S))+
  theme(legend.position="none")

process_2_HR=ggplot(pair_1_2,aes(x=time))+
  geom_line(aes(y=HR1S,color="#3366cc"))+
  geom_line(aes(y=HR2S))+
  theme(legend.position="none")

process_3_HR=ggplot(pair_1_3,aes(x=time))+
  geom_line(aes(y=HR1S,color="#3366cc"))+
  geom_line(aes(y=HR2S))+
  theme(legend.position="none")

process_1_Resp=ggplot(pair_1_1,aes(x=time))+
  geom_line(aes(y=Resp1S,color="#3366cc"))+
  geom_line(aes(y=Resp2S))+
  theme(legend.position="none")

process_2_Resp=ggplot(pair_1_2,aes(x=time))+
  geom_line(aes(y=Resp1S,color="#3366cc"))+
  geom_line(aes(y=Resp2S))+
  theme(legend.position="none")

process_3_Resp=ggplot(pair_1_3,aes(x=time))+
  geom_line(aes(y=Resp1S,color="#3366cc"))+
  geom_line(aes(y=Resp2S))+
  theme(legend.position="none")

gridExtra::grid.arrange( process_1_HR, process_2_HR, process_3_HR, process_1_Resp,process_2_Resp,process_3_Resp,ncol=3)
```
- Can you eye-ball which condition if any displays more physiological coordination?

- R  crqa on heart rate and respiration data (find parameters, r  crqa)
```{r crqa}
#list needed for optimizeParam fuction
par = list(lgM =  50, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip")

#get parameters for rqa - delay, emddim and radius
parameters = optimizeParam(pair_1_1$HR1S,pair_1_1$HR2S, par, min.rec = 0, max.rec = 4.5)
#returns NAs most of the time so choose some random for now
parameters = list(delay=45,emddim=3,radius=1)

#perform rqa - file needs to be there twice because crqa is designed for comparing two timeseries)
results=crqa(pair_1_1$HR1S,pair_1_1$HR2S,delay=parameters$delay,embed=parameters$emddim,radius=parameters$radius,normalize=0,rescale=0,mindiagline = 2,minvertline = 2)

results

#make the plot
RP=results$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP))
cols = c("white","blue4")
image(RP, xlab = "", ylab = "", col = cols)
```
- Does this tell you more than just eyeballing the plots?

### Systematically pre-process the data
- Loop through all the files (either with a loop or with a f ction), check which files should be excluded, if any, and save the pre-processed time-series. Tip: plot and visually inspect the data to figure out which should be excluded.
```{r preprocessing function(s)}
#remove outliers function
rm_outliers = function (data) {
  removeOuts <- function(ts, threshold) {
    ts[ts > (mean(ts, na.rm = T) + (threshold * sd(ts, na.rm = T))) |
         ts < (mean(ts, na.rm = T) - (threshold * sd(ts, na.rm = T)))] = mean(ts, na.rm =
                                                                                T)
    return(ts)
  }
  
  treshold_HR=1.5
  treshold_Resp=1.5
  
  data$HR1 = removeOuts(data$HR1, treshold_HR)
  data$HR2 = removeOuts(data$HR2, treshold_HR)
  data$Resp1 = removeOuts(data$Resp1,  treshold_Resp)
  data$Resp2 = removeOuts(data$Resp2,  treshold_Resp)
  
  return(data)
}

#downsampling function
downsample = function (data) {
  pacman::p_load(groupdata2)
  data = data %>%
  group(n = 100, method = 'greedy') %>%
  summarise(
    time = mean(time, na.rm = T),
    HR1 = mean(HR1, na.rm = T),
    HR2 = mean(HR2, na.rm = T),
    Resp1 = mean(Resp1, na.rm = T),
    Resp2 = mean(Resp2, na.rm = T)
  )
  
  return(data)
}

#scaling function
scale_fun = function (data) {
  data$Resp1S = scale(data$Resp1)
  data$Resp2S = scale(data$Resp2)
  data$HR1S = scale(data$HR1)
  data$HR2S = scale(data$HR2)
  
  return(data)
}

plotting_HR = function (data) {
  #plot HRs
  HR=ggplot(data, aes(x = time)) +
    geom_line(aes(y = HR1S, color = "deepskyblue3")) +
    geom_line(aes(y = HR2S)) +
    theme(legend.position = "none")
  
  return(HR)
}

plotting_Resp = function(data) {
    #plot Respirations
  Resp=ggplot(data,aes(x=time))+
    geom_line(aes(y=Resp1S,color="deepskyblue3"))+
    geom_line(aes(y=Resp2S))+
    theme(legend.position="none")
  
  return(Resp)
}

 testing=rm_outliers(pair_1_1)
testing=downsample(testing)
# testing=scale_fun(testing)
# test_HR=plotting_HR(testing)
# test_HR
# test_Resp = plotting_Resp(testing)
# test_Resp
# gridExtra::grid.arrange(test_HR,test_Resp)

#functions give me the same data back

preprocess = function (data) {
  d=rm_outliers(data)
  d=downsample(d)
  d=scale_fun(d)
  
  return(d)
}
```

```{r loop & preprocess}
files_list = list.files(path="CleanData", full.names = T)
n=1
for (f in files_list) {
  filename = f
  save_directory="PreprocessedData/"
  filename=substr(filename,11,50)
  file_path = paste(save_directory,filename,sep="")
  
  dat = read.csv(file=f, header=T)
  data=preprocess(dat)
  write.csv(data,file_path,row.names = F)
  
  #and clean the dataframe for next round
  data=data.frame()
  
  print(n)
  n=1+n
}

```

```{r plot and remove bad files}
#list of preprocessed files
prep_files=list.files(path='PreprocessedData',full.names = T)


#run a loop to export plots into directory
for (f in prep_files) {
  d=read.csv(file=f,header=T)
  HR_plot=plotting_HR(data=d)
  Resp_plot= plotting_Resp(data=d)
  
  #create new filename and directory for plots
  info=get_info(f)
  name=paste(info$study,info$group,info$trial,info$condition,sep="_")
  #add a directory
  file_path=paste("Plots/", name,".png", sep="")
  
  png(filename = file_path)
  gridExtra::grid.arrange(HR_plot,Resp_plot)
  dev.off()
}

#now these plots are saved in the folder and I can view them outside of R and delete bad files

#to get a nice table of excluded files list files in fullData and PreprocessedData folders
all_prep_d=data.frame(files=list.files("PreprocessedAll"))
used_prep_d=as.factor(list.files("PreprocessedData"))

#1-2 will give me the bad files
`%not in%` <- function (x, table) is.na(match(x, table, nomatch=NA_integer_))

removed_data=subset(all_prep_d, files %not in% used_prep_d)
write.csv2(removed_data,"removed_d.csv",row.names = F)
```


- Run  crqa on all the pre-processed time-series and save the output (don't forget to add columns with study, group, condition and trial). Tip: remember to first assess optimal parameters (dimensions, delay, radius) across all timeseries. Tip: it will often fail, just take whatever parameters you get, select optimal across timeseries parameters and r  crqa on all timeseries with those. Tip: double check the rr. When I ran the loop, I got very low rr, so I adjusted the radius  til the average of rr across all pairs was approx. 4%. (radius=median+1.2)

```{r extract info}
get_info= function(file) {
  
  pattern="[[:punct:]]" #regex for punctuation so I'll split the string by underscores
  name= file %>% stringr::str_split(pattern) %>% unlist()
  study= name[2]
  group=name[3]
  trial=name[4]
  condition= name[5]
  
  info= data.frame(study, group, trial, condition) #save them to a dataframe
  return(info)
}

get_info(string)

```

```{r get parameters}
get_param_HR = function (dat) {
    #list needed for running the optimizeParam function
  par = list(lgM = 30, steps = seq(1, 6, 1), radiusspan = 100, radiussample = 100, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, fnnpercent = 10, typeami = "mindip")

  param = optimizeParam(dat$HR1S,dat$HR2S, par, min.rec = 2, max.rec = 8)
  if (is.null(param)) {
    param=list(radius=NA,emddim=NA,delay=NA)
  }
  return(param)
}

get_param_Resp = function (dat) {
    #list needed for running the optimizeParam function
  par = list(lgM = 30, steps = seq(1, 6, 1), radiusspan = 100, radiussample = 100, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, fnnpercent = 10, typeami = "mindip")
  
  param = optimizeParam(dat$Resp1S,dat$Resp2S, par, min.rec = 2, max.rec = 8)
  
  if (is.null(param)) {
    param=list(radius=NA,emddim=NA,delay=NA)
  }
  
  return(param)
}

#load the preprocessed data
prep_files=list.files(path='PreprocessedData',full.names = T)

#get parameters from all and choose the common ones
all_param_HR = data.frame()
all_param_Resp = data.frame()

n=1
for (f in prep_files) {
  d = read.csv(file=f, header=T)
  param_HR=try(get_param_HR(d),silent = T)
  param_Resp=try(get_param_Resp(d),silent = T)
  all_param_HR=rbind(all_param_HR,param_HR)
  all_param_Resp=rbind(all_param_Resp,param_Resp)
  
  print(n)
  n=n+1
}

all_param_HR=na.omit(all_param_HR)

#turn all to numeric, for some reason it's character
all_param_HR=as.data.frame(sapply(all_param_HR,as.numeric))
all_param_HR=na.omit(all_param_HR)

all_param_Resp=na.omit(all_param_Resp)
all_param_Resp=as.data.frame(sapply(all_param_Resp,as.numeric))
all_param_Resp=na.omit(all_param_Resp)

param_all_HR = list(
  delay=median(all_param_HR$delay),
  emddim=median(all_param_HR$emddim),
  radius=median(all_param_HR$radius)
)
param_all_HR
# $delay
# [1] 5
# 
# $emddim
# [1] 20
# 
# $radius
# [1] 2.147141


param_all_Resp = list(
  delay=median(all_param_Resp$delay),
  emddim=median(all_param_Resp$emddim),
  radius=median(all_param_Resp$radius)
)

param_all_Resp #delay=9; emddim=2; radius=0.37436
```

```{r run CRQA}
#function to run crqa both for resp and HR and save output

get_rqa_HR = function (df) {
  param = param_all_HR
  results=
    tryCatch(
      #this is the try part if it gets error here it will move to the error part
      {crqa(df$HR1S,df$HR2S,delay=param$delay,embed=param$emddim,radius=param$radius,normalize=0,rescale=0,mindiagline = 2,minvertline = 2)
        },
      #error part - if function fails this function will be executed instead
      error=function(cond){
        #return results with only NAs
        results_fail=data.frame(RR=NA,DET=NA,maxL=NA,L=NA,ENTR=NA,LAM=NA,TT=NA)
        return(results_fail)
      }
  )
  delay=param$delay
  embed=param$emddim
  radius=param$radius
  RR_HR = results$RR
  DET_HR = results$DET
  maxL_HR = results$maxL #maximal trajectory
  L_HR = results$L #mean trajectory
  ENTR_HR = results$ENTR
  LAM_HR=results$LAM
  TT_HR = results$TT
  rqa_df = data.frame(delay,embed,radius,RR_HR,DET_HR,maxL_HR,L_HR,ENTR_HR,LAM_HR,TT_HR)
  
  return(rqa_df)
}

get_rqa_Resp= function (df) {
  param = param_all_Resp
  results=
    tryCatch(
      #this is the try part if it gets error here it will move to the error part
      {crqa(df$Resp1S,df$Resp2S,delay=param$delay,embed=param$emddim,radius=param$radius,normalize=0,rescale=0,mindiagline = 2,minvertline = 2)
        },
      #error part - if function fails this function will be executed instead
      error=function(cond){
        #return results with only NAs
        results_fail=data.frame(RR=NA,DET=NA,maxL=NA,L=NA,ENTR=NA,LAM=NA,TT=NA)
        return(results_fail)
      }
  )
  
  delay=param$delay
  embed=param$emddim
  radius=param$radius
  RR_Resp = results$RR
  DET_Resp = results$DET
  maxL_Resp = results$maxL #maximal trajectory
  L_Resp = results$L #mean trajectory
  ENTR_Resp = results$ENTR
  LAM_Resp=results$LAM
  TT_Resp = results$TT
  rqa_df = data.frame(delay,embed,radius,RR_Resp,DET_Resp,maxL_Resp,L_Resp,ENTR_Resp,LAM_Resp,TT_Resp)
  return(rqa_df)
}

get_rqa_Resp(testing)

final_results = data.frame()
n=1
for (f in prep_files) {
  dat = read.csv(file=f,header = T)
  
  rqaHR=get_rqa_HR(dat)
  rqaResp=get_rqa_Resp(dat)
  info=get_info(file=f)
  
  result=cbind(info,rqaHR,rqaResp)
  final_results=rbind(final_results,result)
  
  print(n)
  n=n+1
}
mean(final_results$RR_HR)
mean(final_results$RR_Resp)

write.csv(final_results, "final_results.csv", row.names = F)
```

### Creating controls: shuffled controls
 - loop through all pairs and conditions
 - shuffle the timeseries (take a timeseries and rearrange its values in a random order). Tip check the sample() f ction
 - r  crqa and save the output. NB. which delay, embed, radius parameters should you use?
 - statistically compare the crqa indexes in real and shuffled pairs
 
```{r shuffle}
#function for creating a shuffled data
shuffle = function (f) {
  dat=read.csv(f,header = T)
  output=data.frame(
    time = dat$time,
    HR1S_s = sample(dat$HR1S),
    HR2S_s = sample(dat$HR2S),
    Resp1S_s = sample(dat$Resp1S),
    Resp2S_s = sample(dat$Resp2S)
  )
  
  filename = f
  save_directory="ShuffledData/"
  filename=substr(filename,18,50)
  file_path = paste(save_directory,filename,sep="")
  
  write.csv(output,file_path,row.names = F)
}

lapply(prep_files,shuffle)
```

```{r run shuffled crqa}
#make list of shuffled files
shuffled_list = list.files("ShuffledData", full.names = T)

final_results_shuffled = data.frame()
n=1
for (f in shuffled_list) {
  dat = read.csv(file=f,header = T)
  
  rqaHR=get_rqa_HR(dat)
  rqaResp=get_rqa_Resp(dat)
  info=get_info(file=f)
  
  result=cbind(info,rqaHR,rqaResp)
  final_results_shuffled=rbind(final_results_shuffled,result)
  print(n)
  n=n+1
}

write.csv(final_results_shuffled,"final_results_shuffled.csv",row.names=F)


```

```{r compare shuffle}

final_results$type = factor("normal")
final_results_shuffled$type = factor("shuffle")




#merge them into one df
normal_shuffled = rbind(final_results,final_results_shuffled)

library(lmerTest)
RR_HR_shuf = lmer(RR_HR ~ type + (1|group),normal_shuffled)
summary(RR_HR_shuf) #not significant

DET_HR_shuf = lmer(DET_HR ~ type+(1|group),normal_shuffled)
summary(DET_HR_shuf) #significant

ENTR_HR_shuf = lmer(ENTR_HR ~ type+(1|group),normal_shuffled)
summary(ENTR_HR_shuf) #significant

L_HR_shuf = lmer(L_HR ~ type+(1|group),normal_shuffled)
summary(L_HR_shuf) #significant

maxL_HR_shuf = lmer(maxL_HR ~ type+(1|group),normal_shuffled)
summary(maxL_HR_shuf) #significant

LAM_HR_shuf = lmer(LAM_HR ~ type+(1|group),normal_shuffled)
summary(LAM_HR_shuf) #significant

TT_HR_shuf = lmer(TT_HR ~ type+(1|group),normal_shuffled)
summary(TT_HR_shuf) #significant


#Respiration now
RR_Resp_shuf = lmer(RR_Resp ~ type+(1|group),normal_shuffled)
summary(RR_Resp_shuf) #significant

DET_Resp_shuf = lmer(DET_Resp ~ type+(1|group),normal_shuffled)
summary(DET_Resp_shuf) #significant

ENTR_Resp_shuf = lmer(ENTR_Resp ~ type+(1|group),normal_shuffled)
summary(ENTR_Resp_shuf) #significant

L_Resp_shuf = lmer(L_Resp ~ type+(1|group),normal_shuffled)
summary(L_Resp_shuf) #significant

maxL_Resp_shuf = lmer(maxL_Resp ~ type+(1|group),normal_shuffled)
summary(maxL_Resp_shuf) #significant

LAM_Resp_shuf = lmer(LAM_Resp ~ type+(1|group),normal_shuffled)
summary(LAM_Resp_shuf) #significant

TT_Resp_shuf = lmer(TT_Resp ~ type+(1|group),normal_shuffled)
summary(TT_Resp_shuf) #significant
```

### TRICKY! Creating controls: surrogate pair controls
 - Per each real pair, identify at least one surrogate pair (matching one of the participants, with somebody doing the same task, but in a different pair). Tip: Celine will share a commented script
 - Run  crqa on all the surrogate pairs and save the output. NB. which delay, embed, radius parameters should you use?
 - Test whether crqa shows a difference between real and surrogate pairs
 
```{r}
#first find possible combinations within two files
#should be 4 but remember you suck in math especially simple math
#create vector with 4 persons in the files f=file p=participant
people=c("f1p1", "f1p2", "f2p1", "f2p2")
combn(people,m=2) #6 - 2 (same file) => 4
#f1p1+f2p1 , f1p1+f2p2 , f1p2+f2p1, f1p2+f2p2

#conditions differed slighlty between study 1 and to so the pairs can be only within 1 study

#start with study 1, less files
study1_flist = list.files(path="PreprocessedData",pattern="Study1",full.names = T)

#extract info from files
inf=data.frame()
for (i in study1_flist) {
  info=get_info(i)
  inf=rbind(inf,info)
}

#extract only group numbers
groups = inf$group
#get rid of "G""
groups=substr(groups,2,4)

#get unique groups
groups = as.numeric(unique(groups))

#create all possible combinations and save as data frame
combinations=groups %>% combs(m=2) %>%as.data.frame()

# #now create also mirrored combinations i.e. instead 1 and 2 => 2 and 1
# mirror=data.frame(V1=combinations$V2,V2=combinations$V1)
# 
# #merge them with combinations to have really all possible combinations
# combinations = rbind(combinations,mirror)

#list all conditions that are in that study
conditions=unique(as.character(inf$condition))

#loop through conditions so that it gets every combination of group and condition
for(cond in conditions) {
  #loop through all combinations of groups in surrogate df
  for (g in 1:nrow(combinations)) {
    #create filename to read in from g
    file1 = paste("Study1_G", combinations$V1[g],sep ="")
    file2 = paste("Study1_G", combinations$V2[g],sep ="")
    
    #from list of files extract those that match file1&2 +condition
    file1 = try(study1_flist[grepl(file1,study1_flist) & grepl(cond,study1_flist)])
    file2 = try(study1_flist[grepl(file2,study1_flist) & grepl(cond,study1_flist)])
    
        #some combinations doesnt exist because those were the bad files so if that happens, the following parts will be skipped
    if (isempty(file1)==FALSE & isempty(file2)==FALSE) {
 #read the files in
      dat_1 = read.csv(file1, header=T)
      dat_2 = read.csv(file2, header=T)
      
      
      #make sure they have the same lenght so that you can run crqa on them
      if (nrow(dat_1)>nrow(dat_2)){
        dat_1=dat_1[1:nrow(dat_2),]
      } else {
        dat_2=dat_2[1:nrow(dat_1),]
      }
      
      #create new files that combine data from 4 people
      #dat1_1 + dat2_2
      combination_1=data.frame(Resp1=dat_1$Resp1,Resp2=dat_2$Resp2,HR1=dat_1$HR1,HR2=dat_2$HR2,Resp1S=dat_1$Resp1S,Resp2S=dat_2$Resp2S,HR1S=dat_1$HR1S,HR2S=dat_2$HR2S)
      
      #dat_2_1 + dat_1_2
      combination_2=data.frame(Resp1=dat_2$Resp1,Resp2=dat_1$Resp2,HR1=dat_2$HR1,HR2=dat_1$HR2,Resp1S=dat_2$Resp1S,Resp2S=dat_1$Resp2S,HR1S=dat_2$HR1S,HR2S=dat_1$HR2S)
      
      #dat_1_1 + dat_2_1
      combination_3=data.frame(Resp1=dat_1$Resp1,Resp2=dat_2$Resp1,HR1=dat_1$HR1,HR2=dat_2$HR1,Resp1S=dat_1$Resp1S,Resp2S=dat_2$Resp1S,HR1S=dat_1$HR1S,HR2S=dat_2$HR1S)
      
      #dat_2_2 + dat_1_2
      combination_4=data.frame(Resp1=dat_2$Resp2,Resp2=dat_1$Resp2,HR1=dat_2$HR2,HR2=dat_1$HR2,Resp1S=dat_2$Resp2S,Resp2S=dat_1$Resp2S,HR1S=dat_2$HR2S,HR2S=dat_1$HR2S)
      
      #create variable with directory name to save new files
      save_directory = "SurrogateData/"
      
      #create names for the combined files
      combination_1_name = paste0(save_directory,"Study1_",combinations$V1[g],"_and_",combinations$V2[g],"_v1_",cond,".csv")
      combination_2_name = paste0(save_directory,"Study1_",combinations$V1[g],"_and_",combinations$V2[g],"_v2_",cond,".csv")
      combination_3_name = paste0(save_directory,"Study1_",combinations$V1[g],"_and_",combinations$V2[g],"_v3_",cond,".csv")
      combination_4_name = paste0(save_directory,"Study1_",combinations$V1[g],"_and_",combinations$V2[g],"_v4_",cond,".csv")
      
      #save the new files
      write.csv(x=combination_1,file=combination_1_name)
      write.csv(x=combination_2,file=combination_2_name)
      write.csv(x=combination_3,file=combination_3_name)
      write.csv(x=combination_4,file=combination_4_name)
    } else {
      
      print("Such combination doesn't exist. I'm moving on.")
      
      }
  }
}
```


```{r}
study2_flist = list.files(path="PreprocessedData",pattern="Study2",full.names = T)

#extract info from files
inf=data.frame()
for (i in study2_flist) {
  info=get_info(i)
  inf=rbind(inf,info)
}

#extract only group numbers
groups = inf$group
#get rid of "G""
groups=substr(groups,2,4)

#get unique groups
groups = as.numeric(unique(groups))

#create all possible combinations and save as data frame
combinations=groups %>% combs(m=2) %>%as.data.frame()

#now create also mirrored combinations i.e. instead 1 and 2 => 2 and 1
# mirror=data.frame(V1=combinations$V2,V2=combinations$V1)
# 
# #merge them with combinations to have really all possible combinations
# combinations = rbind(combinations,mirror)

#list all conditions that are in that study
conditions=unique(as.character(inf$condition))

#loop through conditions so that it gets every combination of group and condition
for(cond in conditions) {
  #loop through all combinations of groups in surrogate df
  for (g in 1:nrow(combinations)) {
    #create filename to read in from g
    file1 = paste("Study2_G", combinations$V1[g],sep ="")
    file2 = paste("Study2_G", combinations$V2[g],sep ="")
    
    #from list of files extract those that match file1&2 +condition
    file1 = try(study2_flist[grepl(file1,study2_flist) & grepl(cond,study2_flist)])
    file2 = try(study2_flist[grepl(file2,study2_flist) & grepl(cond,study2_flist)])
    
        #some combinations doesnt exist because those were the bad files so if that happens, the following parts will be skipped
    if (isempty(file1)==FALSE & isempty(file2)==FALSE) {
 #read the files in
      dat_1 = read.csv(file1, header=T)
      dat_2 = read.csv(file2, header=T)
      
      
      #make sure they have the same lenght so that you can run crqa on them
      if (nrow(dat_1)>nrow(dat_2)){
        dat_1=dat_1[1:nrow(dat_2),]
      } else {
        dat_2=dat_2[1:nrow(dat_1),]
      }
      
      #create new files that combine data from 4 people
      #dat1_1 + dat2_2
      combination_1=data.frame(Resp1=dat_1$Resp1,Resp2=dat_2$Resp2,HR1=dat_1$HR1,HR2=dat_2$HR2,Resp1S=dat_1$Resp1S,Resp2S=dat_2$Resp2S,HR1S=dat_1$HR1S,HR2S=dat_2$HR2S)
      
      #dat_2_1 + dat_1_2
      combination_2=data.frame(Resp1=dat_2$Resp1,Resp2=dat_1$Resp2,HR1=dat_2$HR1,HR2=dat_1$HR2,Resp1S=dat_2$Resp1S,Resp2S=dat_1$Resp2S,HR1S=dat_2$HR1S,HR2S=dat_1$HR2S)
      
      #dat_1_1 + dat_2_1
      combination_3=data.frame(Resp1=dat_1$Resp1,Resp2=dat_2$Resp1,HR1=dat_1$HR1,HR2=dat_2$HR1,Resp1S=dat_1$Resp1S,Resp2S=dat_2$Resp1S,HR1S=dat_1$HR1S,HR2S=dat_2$HR1S)
      
      #dat_2_2 + dat_1_2
      combination_4=data.frame(Resp1=dat_2$Resp2,Resp2=dat_1$Resp2,HR1=dat_2$HR2,HR2=dat_1$HR2,Resp1S=dat_2$Resp2S,Resp2S=dat_1$Resp2S,HR1S=dat_2$HR2S,HR2S=dat_1$HR2S)
      
      #create variable with directory name to save new files
      save_directory = "SurrogateData/"
      
      #create names for the combined files
      combination_1_name = paste0(save_directory,"Study2_",combinations$V1[g],"_and_",combinations$V2[g],"_v1_",cond,".csv")
      combination_2_name = paste0(save_directory,"Study2_",combinations$V1[g],"_and_",combinations$V2[g],"_v2_",cond,".csv")
      combination_3_name = paste0(save_directory,"Study2_",combinations$V1[g],"_and_",combinations$V2[g],"_v3_",cond,".csv")
      combination_4_name = paste0(save_directory,"Study2_",combinations$V1[g],"_and_",combinations$V2[g],"_v4_",cond,".csv")
      
      #save the new files
      write.csv(x=combination_1,file=combination_1_name)
      write.csv(x=combination_2,file=combination_2_name)
      write.csv(x=combination_3,file=combination_3_name)
      write.csv(x=combination_4,file=combination_4_name)
    } else {
      
      print("Such combination doesn't exist. I'm moving on.")
      
      }
  }
}
```

```{r crqa on surrogate}
#tweak the get_info function to work on surrogate correctly
get_info_surrogate = function(file) {
  pattern="[[:punct:]]" #regex for punctuation so I'll split the string by underscores
  name=file %>% stringr::str_split(pattern) %>% unlist()
  study=name[2]
  group=paste(name[3],name[4],name[5],sep="_")
  trial=name[6]
  condition=name[7]
  
  info=as.data.frame(cbind(study,group,trial,condition))
  return(info)
}

surrogates_list = list.files("SurrogateData", full.names = T)


final_results_surrogate = data.frame()
n=1
for (f in surrogates_list) {
  dat = read.csv(file=f,header = T)
  
  rqaHR=get_rqa_HR(dat)
  rqaResp=get_rqa_Resp(dat)
  info=get_info_surrogate(file=f)
  
  result=cbind(info,rqaHR,rqaResp)
  final_results_surrogate=rbind(final_results_surrogate,result)
  
  print(n)
  n=1+n
}

write.csv(final_results_surrogate,"final_results_surrogate.csv", row.names = F)
```

```{r difference?}

final_results_surrogate$type = factor("surrogate")

#merge them into one df
normal_surrogate = rbind(final_results,final_results_surrogate)
normal_surrogate$condition = relevel(normal_surrogate$condition,ref="Synchronous")

RR_HR_sur = lmer(RR_HR ~ type*condition+(1|group),normal_surrogate)
summary(RR_HR_sur) #not significant
difflsmeans(RR_HR_sur) #no

DET_HR_sur = lmer(DET_HR ~ type*condition+(1|group),normal_surrogate)
summary(DET_HR_sur) # no
difflsmeans(DET_HR_sur) #no

ENTR_HR_sur = lmer(ENTR_HR ~ type*condition+(1|group),normal_surrogate)
summary(ENTR_HR_sur) #no
difflsmeans(ENTR_HR_sur) #no

L_HR_sur = lmer(L_HR ~ type*condition+(1|group),normal_surrogate)
summary(L_HR_sur) #no
difflsmeans(L_HR_sur) #no

maxL_HR_sur = lmer(maxL_HR ~ type*condition+(1|group),normal_surrogate)
summary(maxL_HR_sur) #no
difflsmeans(maxL_HR_sur) #normSelfPaced-surSelfPaced

LAM_HR_sur = lmer(LAM_HR ~ type*condition+(1|group),normal_surrogate)
summary(LAM_HR_sur) #no
difflsmeans(LAM_HR_sur)

TT_HR_sur = lmer(TT_HR ~ type*condition+(1|group),normal_surrogate)
summary(TT_HR_sur) #no
difflsmeans(TT_HR_sur) #no


#Respiration now
RR_Resp_sur = lmer(RR_Resp ~ type*condition+(1|group),normal_surrogate)
summary(RR_Resp_sur) #no, good I can continue
difflsmeans(RR_Resp_sur) #no

DET_Resp_sur = lmer(DET_Resp ~ type*condition +(1|group),normal_surrogate)
summary(DET_Resp_sur) #no
difflsmeans(DET_Resp_sur) #no

ENTR_Resp_sur = lmer(ENTR_Resp ~ type*condition+(1|group),normal_surrogate)
summary(ENTR_Resp_sur) #significant condition but interaction no
difflsmeans(ENTR_Resp_sur) #no

L_Resp_sur = lmer(L_Resp ~ type*condition+(1|group),normal_surrogate)
summary(L_Resp_sur) #no interaction
difflsmeans(L_Resp_sur) #no

maxL_Resp_sur = lmer(maxL_Resp ~ type*condition+(1|group),normal_surrogate)
summary(maxL_Resp_sur) #no
difflsmeans(maxL_Resp_sur) #SelfPaced-norm x sur

LAM_Resp_sur = lmer(LAM_Resp ~ type*condition+(1|group),normal_surrogate)
summary(LAM_Resp_sur) #no
difflsmeans(LAM_Resp_sur) #no

TT_Resp_sur = lmer(TT_Resp ~ type*condition+(1|group),normal_surrogate)
summary(TT_Resp_sur) #no
difflsmeans(TT_Resp_sur)

#no difference so if any coordination will be find than only because of doing the same task
#exceptions: maxL_HR_sur: SelfPaced
            #maxL_Resp_sur: SelfPaced 
```



### Testing effects of conditions
 - make a (probably  underpowered) mixed model testing effects of the different conditions on heart rate and respiration coordination
 - N.B: would it make sense to include surrogate pairs? and if so how? what would that tell you?
 
 
```{r effect of condition}
#make Synchronous baseline, where we expect coordination only because of computer determined rhythm
final_results$condition = relevel(final_results$condition,ref="Synchronous")

#first models for HR
model_RR_HR = lmer(RR_HR ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_RR_HR) #not significant so I can continue
difflsmeans(model_RR_HR) #no

model_DET_HR = lmer(DET_HR ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_DET_HR) #no
difflsmeans(model_DET_HR) #no

model_ENTR_HR = lmer(ENTR_HR ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_ENTR_HR) #no
difflsmeans(model_ENTR_HR) #no

model_L_HR = lmer(L_HR ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_L_HR) #no
difflsmeans(model_L_HR) #no

model_maxL_HR = lmer(maxL_HR ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_maxL_HR) #SelfPaced and TurnTaking
difflsmeans(model_maxL_HR) #yes Synchronous-SelfPaced, Synchronous-TurnTaking, SelfPaced-Conversation, SelfPaced-TurnTaking

model_LAM_HR = lmer(LAM_HR ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_LAM_HR) #no
difflsmeans(model_LAM_HR) #yes TurnTaking-SelfPaced


model_TT_HR = lmer(TT_HR ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_TT_HR) #no
difflsmeans(model_TT_HR) #no


#now models for respiration
model_RR_Resp = lmer(RR_Resp ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_RR_Resp) #TurnTaking
difflsmeans(model_RR_Resp) #yes - Synchronous-TurnTaking, TurnTaking-SelfPaced - these cannot be trusted, ignore them later

model_DET_Resp = lmer(DET_Resp ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_DET_Resp) #no
difflsmeans(model_DET_Resp) #no

model_ENTR_Resp = lmer(ENTR_Resp ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_ENTR_Resp) #TurnTaking and Conversation
difflsmeans(model_ENTR_Resp) #Synchronous-TurnTaking (nope), Synchronous-Conversation, TurnTaking-SelfPaced (nope), SelfPaced-Conversation


model_L_Resp = lmer(L_Resp ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_L_Resp) #TurnTaking and Conversation
difflsmeans(model_L_Resp) #Synchronous-TurnTaking (nope), Synchronous-Conversation, TurnTaking-SelfPaced (nope), SelfPaced-Conversation

model_maxL_Resp = lmer(maxL_Resp ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_maxL_Resp) #no
difflsmeans(model_maxL_Resp) #no

model_LAM_Resp = lmer(LAM_Resp ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_LAM_Resp) #no
difflsmeans(model_LAM_Resp) #no

model_TT_Resp = lmer(TT_Resp ~ condition+(1|group)+(1|study), data=final_results,REML=F)
summary(model_TT_Resp) #Conversation
difflsmeans(model_TT_Resp) #Synchronous-Conversation, TurnTaking-SelfPaced (nope), SelfPaced-Conversation
```
 
Now I'm including surrogate pairs (using merged dataframe) and type as random effect (no systematic difference was found). Because there is no difference between real pairs and surrogate (in no condition) I can use all these data to increase power of the analysis. Because what if the effect I found was just result of underpowered model

```{r +surrogate =more power}

#first models for HR
model_RR_HR = lmer(RR_HR ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate,REML=F)
summary(model_RR_HR) #still good

model_DET_HR = lmer(DET_HR ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate,REML=F)
summary(model_DET_HR) #this made SelfPaced significant

model_ENTR_HR = lmer(ENTR_HR ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate,REML=F)
summary(model_ENTR_HR) #no

model_L_HR = lmer(L_HR ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate,REML=F)
summary(model_L_HR) #no

model_maxL_HR = lmer(maxL_HR ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate,REML=F)
summary(model_maxL_HR) #and now I lost my effect

model_LAM_HR = lmer(LAM_HR ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate,REML=F)
summary(model_LAM_HR) #SelfPaced, this hold up

model_TT_HR = lmer(TT_HR ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate,REML=F)
summary(model_TT_HR) #no


#now models for respiration
model_RR_Resp = lmer(RR_Resp ~ condition+(1|group)+(1|study)+(1|type), data=normal_surrogate)
summary(model_RR_Resp) #and now everythins significant so I can't interpret anything so no sense in carrying on
```



### Effects of respiration coordination on heart rate coordination
 - describe how you would test those.
 Predicting HR from Resp, i.e L of HR predicted from Resp L or RR or DET or whatever
 - Optional: run  the models and report them
```{r effects of resp on HR coordination}
model_HR_Resp_1 = lmer(maxL_HR ~ ENTR_Resp*condition + (1|group)+(1|study),data=normal_surrogate)
summary(model_HR_Resp_1)
#no combination seems to be significant - should I report that???
```
 
 